{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTRASTIVE LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Lambda\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for storing the numpy objects of pairs of images, lables and pairs of images names\n",
    "arr_dict_X_Y_names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in ['train','valid','test']:\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_X.npy', 'rb') as f:\n",
    "         arr_dict_X_Y_names[f'arr_{sample}_X'] = np.load(f)\n",
    "\n",
    "\n",
    "arr_train_X = arr_dict_X_Y_names['arr_train_X']\n",
    "arr_valid_X = arr_dict_X_Y_names['arr_valid_X']\n",
    "arr_test_X = arr_dict_X_Y_names['arr_test_X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in ['train','valid','test']:\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_X_names.npy', 'rb') as f:\n",
    "        arr_dict_X_Y_names[f'{sample}_X_names'] = np.load(f)\n",
    "\n",
    "train_X_names = arr_dict_X_Y_names['train_X_names']\n",
    "valid_X_names = arr_dict_X_Y_names['valid_X_names']\n",
    "test_X_names = arr_dict_X_Y_names['test_X_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in ['train','valid','test']:\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_Y.npy', 'rb') as f:\n",
    "        arr_dict_X_Y_names[f'arr_{sample}_Y'] = np.load(f)\n",
    "\n",
    "arr_train_Y = arr_dict_X_Y_names['arr_train_Y']\n",
    "arr_valid_Y = arr_dict_X_Y_names['arr_valid_Y']\n",
    "arr_test_Y = arr_dict_X_Y_names['arr_test_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function creating pairs\n",
    "def\tmake_pairs(images, labels, image_names):\n",
    "\n",
    "\tpairImages = []\n",
    "\tpairLabels = []\n",
    "\tpairImagesNames = []\n",
    "\tuniqueClasses = np.unique(labels)\n",
    "\n",
    "\tdict_idx = {i:np.where(labels == i)[0] for i in uniqueClasses}\n",
    "\n",
    "\tfor idxA in range(len(images)):\n",
    "\t\tcurrentImage = images[idxA]\n",
    "\t\tlabel = labels[idxA]\n",
    "\t\tcurrentImage_name = image_names[idxA]\n",
    "\n",
    "\t\t#positive pair\n",
    "\t\tidxB = np.random.choice(dict_idx[label])\n",
    "\t\tposImage = images[idxB]\n",
    "\t\tposImage_name = image_names[idxB]\n",
    "\t\tpairImages.append([currentImage, posImage])\n",
    "\t\tpairImagesNames.append([currentImage_name, posImage_name])\n",
    "\t\tpairLabels.append([1])\n",
    "\n",
    "\t\t#negative pair\n",
    "\t\tnegLab = np.random.choice([i for i in dict_idx.keys() if i != label])\n",
    "\t\tnegIdx = np.random.choice(dict_idx[negLab])\n",
    "\t\tnegImage = images[negIdx]\n",
    "\t\tnegImage_name = image_names[negIdx]\n",
    "\t\tpairImages.append([currentImage, negImage])\n",
    "\t\tpairImagesNames.append([currentImage_name, negImage_name])\n",
    "\t\tpairLabels.append([0])\n",
    "\n",
    "\treturn (np.array(pairImages),np.array(pairLabels)), np.array(pairImagesNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pairTrain, labelTrain), pairNamesTrain = make_pairs(arr_train_X, arr_train_Y, train_X_names)\n",
    "(pairValid, labelValid), pairNamesValid = make_pairs(arr_valid_X, arr_valid_Y, valid_X_names)\n",
    "(pairTest, labelTest), pairNamesTest = make_pairs(arr_test_X, arr_test_Y, test_X_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training pairs: 12000\n",
      "Number of validation pairs: 4000\n",
      "Number of test pairs: 4000\n"
     ]
    }
   ],
   "source": [
    "print('Number of training pairs:',len(pairTrain))\n",
    "print('Number of validation pairs:',len(pairValid))\n",
    "print('Number of test pairs:',len(pairTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pairs = {'train': {'pair_imgs': pairTrain, 'pair_imgs_names':pairNamesTrain,'labels':labelTrain},\n",
    "                'valid': {'pair_imgs': pairValid,'pair_imgs_names':pairNamesValid,'labels':labelValid},\n",
    "                'test': {'pair_imgs': pairTest, 'pair_imgs_names':pairNamesTest,'labels':labelTest}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the pairs of cropped images, their names and labels (1/0).\n",
    "for sampl in dict_pairs.keys():\n",
    "    for n in dict_pairs[sampl].keys():\n",
    "       with open(f'./pair_numpys/{sampl}_{n}.npy', 'wb') as f:\n",
    "            np.save(f, dict_pairs[sampl][n])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN model building with contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "\t(featsA, featsB) = vectors\n",
    "    \n",
    "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "\t\tkeepdims=True)\n",
    "\n",
    "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = Input(shape=(224, 224, 3))\n",
    "imgB = Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(inputShape, embeddingDim=48):\n",
    "\tinputs = Input(inputShape)\n",
    "\n",
    "\tx = Conv2D(64, (2, 2),  activation=\"relu\")(inputs)\n",
    "\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\tx = GlobalAveragePooling2D()(x)\n",
    "\toutputs = Dense(embeddingDim)(x)\n",
    "\t\n",
    "\tmodel = Model(inputs, outputs)\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y, preds, margin=1):\n",
    "\n",
    "\ty = tf.cast(y, preds.dtype)\n",
    "\n",
    "\tsquaredPreds = K.square(preds)\n",
    "\tsquaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "\tloss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
    "\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureExtractor = build_siamese_model((224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance)([featsA, featsB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[imgA, imgB], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=contrastive_loss, optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 510s 1s/step - loss: 57.4097 - accuracy: 0.3901 - val_loss: 0.2862 - val_accuracy: 0.2275\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 488s 1s/step - loss: 0.3894 - accuracy: 0.3776 - val_loss: 0.2000 - val_accuracy: 0.2595\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 468s 1s/step - loss: 0.2959 - accuracy: 0.3721 - val_loss: 0.2234 - val_accuracy: 0.2467\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 469s 1s/step - loss: 0.2856 - accuracy: 0.3723 - val_loss: 0.1868 - val_accuracy: 0.2928\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 475s 1s/step - loss: 0.2807 - accuracy: 0.3745 - val_loss: 0.2427 - val_accuracy: 0.2473\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "\t[pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
    "\tvalidation_data=([pairValid[:, 0], pairValid[:, 1]], labelValid[:]),\n",
    "\tepochs=5, verbose = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 49s 363ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([pairTest[:, 0], pairTest[:, 1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSE_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf7e70c757e4f60095653c44545a762e49c6e5d3353dc968e17e829e1045004e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
